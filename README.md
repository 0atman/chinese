# Chinese

The first 1500 Chinese characters to learn according to [Hanzi DB](http://hanzidb.org/character-list/by-frequency) turned into markdown files processable by Obsidian. Obsidian allows us to view all of the markdown files as nodes in a graph with lines to nodes that represent HSK level, stroke count, and radical usage.

![image](https://user-images.githubusercontent.com/3976080/181281358-e90c0ee7-ad5d-4cba-976b-97e9f4a7b4f2.png)

## How to Use

1. Download and install [Obsidian](https://obsidian.md/)
2. Clone this repo
3. Open the repo using Obsidian

## Leave Suggestions as Github Issues!

For the love of God, if you have a better way of algorithmically relating Chinese characters please tell by leaving a Github issue. What I would love is a way to automatically say "well if you know this character why not learn this related one". I did not make the json by hand, but used Google sheets and a program called Intemplator. As long as I can create a csv of 'character' -> 'label that helps create relations' I can extend this system.

### What I've Tried

Radical usage follows the Pareto Principle and stroke count follows a normal distribution, they don't really chunk characters well.

## Behold

![image](https://user-images.githubusercontent.com/3976080/181281308-70b89d7d-a7a6-4492-9cec-971e36b53fd9.png)
